#!/bin/bash

# Preface - code does not discriminate. Plus, if you read manga, let's be honest;
# you've made the mistake of ending up here accidentally once.

function auto_fakku() {
	if [ -n "`echo $1 | grep 'fakku.net/' | sed -e 's/^ *//' -e 's/[[:space:]]*$//'`" ]; then
		# Fakku
		return 1
	fi

	return 0
}

function dl_fakku() {
	folder="`echo $1 | sed -re 's/^.+\///'`"
	mkdir -p $folder
	cd $folder

	wget "$1/read" -O page.htm > /dev/null 2>&1
	echo `grep "window.params.thumbs =" page.htm` > tmp.1

	# First. Escape fixups. Nuke escaped forward slashes
	sed -i 's/\\\//\//g' tmp.1
	# Next. Reformat decl.
	sed -i 's/\];/)/g' tmp.1
	sed -i 's/window.params.thumbs = \[/pages=(/g' tmp.1
	# Next. Nuke '.thumb'
	sed -i 's/\.thumb//g' tmp.1
	# Next. Nuke commas. Still, they can occur in names so we'll carefully filter.
	sed -i 's/","/" "/g' tmp.1
	# Last transform. '/thumbs/' to '/images/'
	sed -i 's/\/thumbs\//\/images\//g' tmp.1

	# Because some pages have unicode escapes (javascript thing ugh) we have to echo the contents of the file
	# to itself to escape them. UGHHHHH

	echo -e `cat tmp.1` > tmp.1

	# Load in the array.
	source tmp.1

	# Download loop-de-loop.

	echo -n "[Fakku] Downloading '$folder' "

	for image in "${pages[@]}"; do
		wget --no-cache -nc -t 0 -w 30 "https:$image" > /dev/null 2>&1
		spinner
	done

	done_spin

	rm tmp.1
	rm page.htm
	
	cd ..
	
	cbz_make $folder
}

function scrape_fakku() {
	echo "[Fakku] Fakku probably won't ever support scraping functionality."
	echo "[Fakku] Everything on there is organized in a strictly one-shot manner."
}
