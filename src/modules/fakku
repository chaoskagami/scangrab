#!/bin/bash
# Copyright (C) 2015  Jon Feldman/@chaoskagami
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>

# Preface - code does not discriminate. Plus, if you read manga, let's be honest;
# you've made the mistake of ending up here accidentally once.

fakku_longname="FAKKU"
fakku_url="https://fakku.net/"
fakku_state=1
fakku_filt=0

auto_fakku() {
	if [ -n "`echo $1 | grep 'fakku.net/' | sed -e 's/^ *//' -e 's/[[:space:]]*$//'`" ]; then
		# Fakku
		return 1
	fi

	return 0
}

dl_fakku() {
	PAGES="$(fetch "$1/read" "-" | grep "window.params.thumbs =")"

	# First. Escape fixups. Nuke escaped forward slashes
	# Next. Reformat decl.
	# Next. Nuke '.thumb'
	# Next. Nuke commas. Still, they can occur in names so we'll carefully filter.
	# Last transform. '/thumbs/' to '/images/'
	PAGEDATA="$(echo $PAGES | sed -e 's/\\\//\//g' -e 's/\];/)/g' -e 's/window.params.thumbs = \[/pages=(/g' -e 's/\.thumb//g' -e 's/","/" "/g' -e 's/\/thumbs\//\/images\//g')"

	# Because some pages have unicode escapes (javascript thing ugh) we have to echo the contents of the file
	# to itself to escape them. UGHHHHH

	DATA="$(printf "$PAGEDATA")"

	folder="$(echo $PAGEDATA | sed -e 's|pages=("//t.fakku.net/images/manga/i/||g' -e 's|/images.*||g' -e 's|_| |g' | entity_to_char)"
	mkdir -p "$folder"
	cd "$folder"

	# Load in the array.
	eval "$DATA"

	# Download loop-de-loop.

	echo -n "[Fakku] Downloading '$folder' "

	CUR=0
	for image in "${pages[@]}"; do
		fetch "https:$image"
		spinner "$CUR"
		CUR=$(( CUR + 1 ))
	done

	done_spin

	cd ..
	
	cbz_make "$folder"
}

scrape_fakku() {
	echo -n "[Fakku] Scraping Chapters..."
	
	fetch "$1" scrape.htm

	grep 'class="content-title"' scrape.htm > batch.txtf

	sed -i 's|^.*href="||g' batch.txtf
	sed -i 's|" title=.*||g' batch.txtf
	sed -i "s/^[[:space:]]*//" batch.txtf
	sed -i "s/[[:space:]]*$//" batch.txtf

	# Links are local.
	sed -i "s|^|https://fakku.net|g" batch.txtf

	# Don't bother doing any re-ordering here, since orders are chaotic.
	cat batch.txtf >> batch.txt

	# Clean up.
	rm scrape.htm batch.txtf

	echo -e "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b[Fakku] Scraped chapters to batch.txt. You can modify this, or pass it to autobatch."
}
