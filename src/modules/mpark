#!/bin/bash
# Copyright (C) 2015  Jon Feldman/@chaoskagami
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>

mpark_longname="MangaPark"
mpark_url="mangapark.me"
# Broken
mpark_state=1
# No filter
mpark_filt=0

auto_mpark() {
	if [ -n "`echo $1 | grep 'mangapark.me/' | sed -e 's/^ *//' -e 's/[[:space:]]*$//'`" ]; then
		# Mangapark
		return 1
	fi

	return 0
}

dl_mpark() {

	sitepage="$1"

	# We need a specific type of URL - the 'all on one page' type. Remove specifiers.
	sitepage=`echo $sitepage | sed "s|/1$||g" | sed "s|/3-1$||g" | sed "s|/6-1$||g" | sed "s|/10-1$||g"`
	
	FETCH="$(fetch "$sitepage" "-")"

	folder="$(echo "$FETCH" | grep '<title>' | sed -e 's/<title>//g' -e 's/ Online For Free.*$//g' -e 's/.* - Read //g')"

	is_done "$folder"
	R=$?
	if [ $R = 1 ]; then
		echo "[MangaPark] Already downloaded. Skipping."
		return 0
	fi

	mkdir -p "$folder"
	cd "$folder"

	declare -a DATA
	DATA=$(echo "$FETCH" | grep 'target="_blank"' - | sed -e '1d' -e 's|^[[:space:]]*<a.*target="_blank" href=||g' -e "s/ title=.*$//" -e "s/\"//g"| tr '\n' ' ')

	echo -n "[Mangapark] Downloading '$folder' "

	CUR=0
	for image in ${DATA[@]}; do
		fetch "$image"
		spinner "$CUR"
		CUR=$(( CUR + 1 ))
	done
	
	spinner_done

	cd ..

	cbz_make "$folder"
}

scrape_mpark() {
	echo -e "[Mangapark] Scraping Chapters..."

	fetch "$1" scrape.htm

	grep 'class="ch sts"' scrape.htm > batch.txtr

	sed -i 's|^.*href="||g' batch.txtr
	sed -i 's|">.*||g' batch.txtr
	sed -i "s/^[[:space:]]*//" batch.txtr
	sed -i "s/[[:space:]]*$//" batch.txtr

	# URLS are local.
	sed -i "s|^|http://mangapark.com|g" batch.txtr

	# We need a specific type of URL - the 'all on one page' type. Remove specifiers.
	sed -i "s|/1$||g" batch.txtr
	sed -i "s|/3-1$||g" batch.txtr
	sed -i "s|/6-1$||g" batch.txtr
	sed -i "s|/10-1$||g" batch.txtr

	# Lines are reverse order.
	cat batch.txtr | reverse_lines >> batch.txt

	# We've scraped a batch file from the URL list. Clean up.
	rm scrape.htm batch.txtr

	echo -e "[Mangapark] Scraped chapters to batch.txt. You can modify this, or pass it to autobatch."
}
