#!/bin/bash
# Copyright (C) 2015  Jon Feldman/@chaoskagami
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>

mpark_longname="MangaPark"
mpark_url="http://mangapark.me/"
# Broken
mpark_state=0
# No filter
mpark_filt=0

auto_mpark() {
	if [ -n "`echo $1 | grep 'mangapark.me/' | sed -e 's/^ *//' -e 's/[[:space:]]*$//'`" ]; then
		# Mangapark
		return 1
	fi

	return 0
}

dl_mpark() {

	sitepage="$1"

	# We need a specific type of URL - the 'all on one page' type. Remove specifiers.
	sitepage=`echo $sitepage | sed "s|/1$||g" | sed "s|/3-1$||g" | sed "s|/6-1$||g" | sed "s|/10-1$||g"`

	# Folder edit works different. URLs are consistent with mangapark, e.g. manga/s1/v1/c1
	# I'm using pipes for clarity.
	folder="$(echo $sitepage | sed -e "s|http\:\/\/||g" | sed -e "s|mangapark\.me\/manga\/||g" | sed -e "s|\/|-|g" | entity_to_char)"
	mkdir -p "$folder"
	cd "$folder"
	
	DATA=$(fetch "$sitepage" "-" | grep 'a target="_blank"' - | sed 's|<em><a target="_blank" href=||g')
	
	echo "$DATA" > tmp.1

	sed -i "s/ title=.*//" tmp.1
	eval "pages=(`cat tmp.1 | tr '\n' ' '`)"

	echo -n "[Mangapark] Downloading '$folder' "

	CUR=0
	for image in "${pages[@]}"; do
		fetch "$image"
		spinner "$CUR"
		CUR=$(( CUR + 1 ))
	done

	rm tmp.1
	
	done_spin

	cd ..

	cbz_make "$folder"
}

scrape_mpark() {
	echo -n "[Mangapark] Scraping Chapters..."

	fetch "$1" scrape.htm

	grep 'class="ch sts"' scrape.htm > batch.txtr

	sed -i 's|^.*href="||g' batch.txtr
	sed -i 's|">.*||g' batch.txtr
	sed -i "s/^[[:space:]]*//" batch.txtr
	sed -i "s/[[:space:]]*$//" batch.txtr

	# URLS are local.
	sed -i "s|^|http://mangapark.com|g" batch.txtr

	# We need a specific type of URL - the 'all on one page' type. Remove specifiers.
	sed -i "s|/1$||g" batch.txtr
	sed -i "s|/3-1$||g" batch.txtr
	sed -i "s|/6-1$||g" batch.txtr
	sed -i "s|/10-1$||g" batch.txtr

	# Lines are reverse order. tac.
	# If whatever we're using has no tac, you're stuck with reverse order.
	tac batch.txtr >> batch.txt || cat batch.txtr >> batch.txt

	# We've scraped a batch file from the URL list. Clean up.
	rm scrape.htm batch.txtr

	echo -e "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b[Mangapark] Scraped chapters to batch.txt. You can modify this, or pass it to autobatch."
}
