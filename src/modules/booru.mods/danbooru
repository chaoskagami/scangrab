#!/bin/bash
# Copyright (C) 2015  Jon Feldman/@chaoskagami
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>

# This should set up any variables needed by this module.

booru_danbooru_init() {
	final[0]="$source/posts.json?tags="
}


# This should build a URL which can download a page; call dl_booru_page,
# And then extract the pages. It should not itself do the download.

booru_danbooru_page() {
	final[4]=$1

	if [ $RESUME = 1 ]; then
		# Assume this is done.
		return 1
	fi

	if [ $is_pool = 0 ]; then
		dl_booru_page "$(echo ${final[@]} | tr -d ' ')" "page${range}.json"

		BEFORE=$(wc -l meta.txt | sed 's| .*||g')
		cat "page${range}.json" | tr ',' "\n" | grep '"id"' | sed 's|.*:||g' >> meta.txt
		AFTER=$(wc -l meta.txt | sed 's| .*||g')

		if [ "$BEFORE" = '' ]; then
			BEFORE=0
		fi
		PAGE_SIZE=$((AFTER - BEFORE))

		# We preprocess metadata.
		cat "page${range}.json" | sed "s|},{|}]\n[{|g" | grep '"id"' > tmp
		mv tmp "page${range}.json"

		LEN=0
		while read line; do
			FIRST=$((PAGE_SIZE - LEN))
			id="$(cat meta.txt | tail -n $FIRST | head -n 1)"
			echo "$line" > meta/meta_${id}.json
			LEN=$((LEN + 1))
		done < "page${range}.json"

		rm "page${range}.json"

		# No more pages.
		if (( BEFORE == AFTER )); then
			return 1
		fi

		# Still more.
		return 0
	else
		final[0]="${source}/pools.json?commit=Search&search[order]=updated_at&search[name_matches]="

		dl_booru_page "$(echo ${final[@]} | tr -d ' ')" "${final[1]}.json"

		cat "${final[1]}.json" | tr ',' "\n" | grep '"post_ids"' | sed -e 's|.*:||g' -e 's|"||g' | tr ' ' "\n" >> meta.txt
	fi
}

# This should download a page's meta info. If there isn't any, it should copy the ID to a file named as the ID.

booru_danbooru_meta() {
	declare -a base
	base[0]="$source/posts/"
	base[1]="${1}.json"

	if [ ! -e "meta_${base[1]}" ]; then
		message="fetch ${1}"
		spinner "${DONE} -> ${LINES}"
		message=""

		dl_booru_page "$(echo ${base[@]} | tr -d ' ')" "meta_${base[1]}"
	fi
}

booru_danbooru_content() {
	declare -a base
	base[0]="$source/posts/"
	base[1]="${1}.json"

	url_img="$(cat "${META_DIR}/meta_${base[1]}" | tr ',' "\n" | grep '"file_url"' | sed -e 's|.*:||g' -e "s|\"||g")"
	file_ext="$(cat "${META_DIR}/meta_${base[1]}" | tr ',' "\n" | grep '"file_ext"' | sed 's|.*:||g')"

	if [ "$file_ext" = "" ] || [ "$url_img" = "" ]; then
		spinner_done
		echo "[Booru] ID:${1} appears to be deleted/hidden. Skipping."

		# ID is deleted. Skip.
		return
	fi

	if [ ! -e "image_${1}.${file_ext}" ]; then
		dl_booru_page "${source}${url_img}" "image_${1}.${file_ext}"
	fi
}
