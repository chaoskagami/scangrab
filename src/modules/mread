#!/bin/bash
# Copyright (C) 2015  Jon Feldman/@chaoskagami
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>

mread_longname="Mangareader"
mread_url="http://www.mangareader.net/"
# Broken
mread_state=0
# No filter
mread_filt=0

auto_mread() {
	if [ -n "`echo $1 | grep 'mangareader.net/' | sed -e 's/^ *//' -e 's/[[:space:]]*$//'`" ]; then
		# Mangareader
		return 1
	fi

	return 0
}

dl_mread() {

	# Folder edit works different. URLs are consistent with mangareader. e.g aho-girl/1
	# I'm using pipes for clarity.
	folder="$(echo $1 | sed -e "s|http\:\/\/||g" | sed -e "s|www\.mangareader\.net\/||g" | sed -e "s|\/|-|g" | entity_to_char)"
	mkdir -p "$folder"
	cd "$folder"

	echo -n "[Mangareader] Blindly Downloading '$folder' "

	IS_404=0
	CUR=0
	PAGES=0

	while [ $IS_404 = 0 ]; do
		# Increment CUR.
		CUR=$(( CUR + 1 ))
	
		PAGEDATA=$(fetch "$1/$CUR" "$CUR.htm")
		IS_404=$?

		if [ $IS_404 = 0 ]; then
			src=`grep '<div id="imgholder">' $CUR.htm | sed "s/^.*src=\"//g" | sed "s/\" alt=.*//g"`
	
			echo $src

			# Get extension of src.
			EXT="${src##*.}"

			fetch "$src" "$CUR.$EXT"
	
			spinner
		fi
	done

	PAGES=$(( CUR - 1 ))

	done_spin

	rm *.htm

	cd ..

	cbz_make "$folder"

}

scrape_mread() {
	echo "[MangaReader] NYI, sorry."
}
