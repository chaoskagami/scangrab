#!/bin/bash
# Copyright (C) 2015  Jon Feldman/@chaoskagami
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>

eh_longname="E-H / ExH"
eh_url="g.e-hentai.org / exhentai.org"
eh_state=1
eh_filt=0
eh_note="Logging in will result in HQ images, cap detection, and if you can, Ex use."

eh_uselogin=1

login_eh() {
	use_cookies=1

	# Lots of extra shat they use to prevent bots. If it gets updated; let me know so I can fix it.

	s_login "UserName" "PassWord" "$1" "$2" "https://forums.e-hentai.org/index.php?act=Login&CODE=01" \
		"CookieDate=1&Privacy=1&b=&bt=&referer=https://forums.e-hentai.org/?act=Login&temporary_https="
	user="$(fetch "https://forums.e-hentai.org/?act=idx" "-" | grep 'Logged in as' | sed -e 's|.*showuser=||' -e 's|<.*||' -e 's|.*>||g')"
	if [ ! "$user" = "" ]; then
		echo -e "\n[E-H] Logged in as: $user"
		exit 0
	else
		echo -e "\n[E-H] Login seems to have failed."
		exit 1
	fi
}

limitcheck_eh() {
	use_cookies=1

	line="$(fetch "http://g.e-hentai.org/home.php" "-" | grep "<p>You are currently at")"

	LIMIT_AT="$(echo $line | sed -e 's|.*<p>You are currently at <strong>||g' -e 's|</strong>.*||g')"
	LIMIT_OF="$(echo $line | sed -e 's|.*</strong> towards a limit of <strong>||g' -e 's|</strong>.*||g')"
	LIMIT_REGEN="$(echo $line | sed -e 's|.*</strong>. This regenerates at a rate of <strong>||g' -e 's|</strong>.*||g')"
}

auto_eh() {
	if [ -n "`echo $1 | grep 'e-hentai.org/' | sed -e 's/^ *//' -e 's/[[:space:]]*$//'`" ]; then
		# E-H
		return 1
	elif [ -n "`echo $1 | grep 'exhentai.org/' | sed -e 's/^ *//' -e 's/[[:space:]]*$//'`" ]; then
		# Ex
		return 1
	fi

	return 0
}

# This returns a code corresponding to whether it can fetch from there, waiting out bans if needed.
check_low_eh() {
	if [ "$check_eh_done" = "1" ]; then
		return 0
	fi

	LOGGEDIN=0
	use_cookies=0
	if [ -f "$COOKIEJAR" ]; then
		if [ -n "`echo $1 | grep 'exhentai.org/' | sed -e 's/^ *//' -e 's/[[:space:]]*$//'`" ]; then
			echo -ne "[E-H] Checking for Ex cookies..."
			grep 'exhentai.org' "$COOKIEJAR" | grep 'ipb_member_id' >/dev/null
			RES=$?
			if [ $RES = 0 ]; then
				echo "yes"
				use_cookies=1
				echo -ne "[E-H] Checking for access..."

				TEMP="$(temp f)"

				# This is a good way of checking if it succeeded.
				fetch "exhentai.org" "$TEMP"
				cat "$TEMP" | grep "The X Makes It Sound Cool" >/dev/null 2>&1
				RES=$?
				if [ ! $RES = 0 ]; then
					echo -n "no, "
					if [ "$(sha256sum "$TEMP" | sed 's| .*||g')" = "a279e4ccd74cffbf20baa41459a17916333c5dd55d23a518e7f10ae1c288644f" ]; then
						echo "panda. <3"
						return 1
					elif [ ! "$(grep 'Your IP address has been temporarily banned' "$TEMP")" = "" ]; then
						echo "tempban. Hilarious."
						ban_eh_wait
						LOGGEDIN=1
						check_low_eh "$1"
						R=$?
						return $R
					else
						echo "format update, world is ending?"
						return 1
					fi
				else
					LOGGEDIN=1
					echo "yes"
				fi

				rm "$TEMP"

				grep "exhentai\.org.*uconfig" "$COOKIEJAR" >/dev/null 2>&1
				RES=$?
				if [ $RES = 0 ]; then
					echo "[E-H] Warning - uconfig is set in cookie jar. This will cause problems."
					if [ "$COOKIEJAR" = "$(pwd)/cookiejar" ]; then
						echo -n "[E-H] Attempting to automatically fix the issue..."
						sed -i "/exhentai\.org.*uconfig/d" "$COOKIEJAR"
						grep "exhentai\.org.*uconfig" "$COOKIEJAR" >/dev/null 2>&1
						RES=$?
						if [ ! $RES = 0 ]; then
							echo "done"
						else
							echo "failed"
						fi
					else
						echo "[E-H] User specified custom cookie jar. Will not automatically fix."
						echo "[E-H] Subsequent download may fail, or get stuck in retry loop."
					fi
				fi
			else
				echo "no"
				echo -ne "[E-H] Checking for E-H cookies..."
				grep 'e-hentai.org' "$COOKIEJAR" | grep 'ipb_member_id' >/dev/null
				RES=$?
				if [ $RES = 0 ]; then
					echo "yes, copying them"
					grep 'e-hentai.org' "$COOKIEJAR" >> cookiejar.edit
					sed 's|e-hentai.org|exhentai.org|g' cookiejar.edit >> cookiejar
					rm cookiejar.edit

					echo -ne "[E-H] Fixed cookies. Checking for access..."
					use_cookies=1

					TEMP="$(temp f)"
					fetch "exhentai.org" "$TEMP"

					grep "The X Makes It Sound Cool" "$TEMP" >/dev/null 2>&1
					RES=$?
					if [ ! $RES = 0 ]; then
						echo -n "no, "
						if [ "$(sha256sum "$TEMP" | sed 's| .*||g')" = "a279e4ccd74cffbf20baa41459a17916333c5dd55d23a518e7f10ae1c288644f" ]; then
							echo "panda. <3"
							return 1
						elif [ ! "$(grep 'Your IP address has been temporarily banned' "$TEMP")" = "" ]; then
							echo "tempban. Hilarious."
							ban_eh_wait
							LOGGEDIN=1
							check_low_eh "$1"
							R=$?
							return $R
						else
							echo "format update, world is ending?"
							return 1
						fi
					else
						LOGGEDIN=1
						echo "yes"
					fi

					rm "$TEMP"

					grep "exhentai\.org.*uconfig" "$COOKIEJAR" >/dev/null 2>&1
					RES=$?
					if [ $RES = 0 ]; then
						echo "[E-H] Warning - uconfig is set in cookie jar. This will cause problems."
						if [ "$COOKIEJAR" = "$(pwd)/cookiejar" ]; then
							echo -n "[E-H] Attempting to automatically fix the issue..."
							sed -i "/exhentai\.org.*uconfig/d" "$COOKIEJAR"
							grep "exhentai\.org.*uconfig" "$COOKIEJAR" >/dev/null 2>&1
							RES=$?
							if [ ! $RES = 0 ]; then
								echo "done"
							else
								echo "failed"
							fi
						else
							echo "[E-H] User specified custom cookie jar. Will not automatically fix."
							echo "[E-H] Subsequent download may fail, or get stuck in retry loop."
						fi
					fi
				else
					echo "no."
					echo "[E-H] No cookies, and you're attempting to fetch an Ex link. Abort."
					return 1
				fi
			fi
		else
			grep 'e-hentai.org' "$COOKIEJAR" | grep 'ipb_member_id' >/dev/null
			RES=$?
			if [ $RES = 0 ]; then
				echo "[E-H] We seem to have cookies...using them."
				LOGGEDIN=1
				use_cookies=1
			fi
		fi
	elif [ -n "`echo $1 | grep 'exhentai.org/' | sed -e 's/^ *//' -e 's/[[:space:]]*$//'`" ]; then
		echo "[E-H] No cookies, and you're attempting to fetch an Ex link. Abort."
		exit 1
	fi

	if [ $LOGGEDIN = 0 ]; then
		echo "[E-H] Not logged in. Expect random failures at anoymous quota cap."
	fi

	check_eh_done=1

	return 0
}

check_eh() {
	# This runs check_low_eh, and will abort on error.
	check_low_eh "$1"
	R=$?
	if [ $R = 1 ]; then
		exit 1
	fi
}

ban_eh_wait() {
	ipbanned="$(fetch "http://g.e-hentai.org/home.php" "-" | grep "^Your IP address has been temporarily banned for")"
	if [ ! "$ipbanned" = "" ]; then
		# Hoo boy, you like downloading stuff, yeah?
		# We're IP banned now until their clock is up. Figure out how long.
		BANSTR="$(echo "$ipbanned" | grep "^Your IP address has been temporarily banned for" | sed -e 's|.*The ban expires in ||' -e 's| and||g' )"

		echo "$BANSTR" | grep "days"
		R=?
		if [ $R = 0 ]; then
			echo "Banned for at least a day, apparently. Just giving up."
			exit 1
		fi
		echo "$BANSTR" | grep "months"
		R=?
		if [ $R = 0 ]; then
			echo "Banned for months? Are you trying to circumvent a ban? It won't work."
			exit 1
		fi
		echo "$BANSTR" | grep "years"
		R=?
		if [ $R = 0 ]; then
			echo "Now would be a good time to find another source to use, Mr. Banned-for-life."
			exit 1
		fi

		declare -a ban_time
		ban_time=($BANSTR)

		ban_str=""

		seconds=0

		for (( i=0 ; i < ${ban_time#} ; i+=2 )); do
			time="${ban_time[$i]}"
			unit="${ban_time[$((i+1))]}"

			ban_str="${ban_str}${time}${unit:0:1}"

			if [ "$unit" = "seconds" ]; then
				seconds=$((seconds + $time))
			elif [ "$unit" = "minutes" ]; then
				time=$((time * 60))
				seconds=$((seconds + $time))
			elif [ "$unit" = "hours" ]; then
				time=$((time * 60 * 60))
				seconds=$((seconds + $time))
			fi
		done

		echo "[E-H] Banned for $ban_str seconds. :<"
		echo -n "[E-H] Sleeping..."

		while (( $seconds > 0 )); do
			seconds=$((seconds - 1))
			sleep 1s
			spinner "${seconds}"
		done

		echo -e "\n[E-H] Resuming..."
	fi
}

dl_eh_wait() {
	ban_eh_wait

	# Check to see (again) if CUR > MAX.
	# If it is, sit around and sleep until we have enough credits.
	limitcheck_eh
	LIMIT_LEFT=$(( LIMIT_OF - LIMIT_AT ))

	# It is totally possible for images to take an absurd chunk of quota.
	# I still have no clue how it is calculated, but I've never seen one
	# image cost more than 100 quota.
	if (( $LIMIT_LEFT < 100 )); then
		message=":#"

		zzz=$(( LIMIT_REGEN * 60 ))

		while [ ! $zzz = 0 ]; do
			spinner "Over, wait ${zzz}s"
			sleep 1s
			zzz=$(( zzz - 1 ))
		done

		limitcheck_eh
		LIMIT_LEFT=$(( LIMIT_OF - LIMIT_AT ))
	fi
}

dl_eh() {
	sitepage=$1

	check_eh "$1"

	if [ $LOGGEDIN = 1 ]; then
		limitcheck_eh
		LIMIT_LEFT=$(( LIMIT_OF - LIMIT_AT ))
		THIS_COUNT=$MAXPAGES
		if [ $LOGGEDIN = 1 ]; then
			THIS_COUNT=$(( MAXPAGES * 100 ))
		fi

		echo "[E-H] Limit check: ${LIMIT_AT} / ${LIMIT_OF}, +${LIMIT_REGEN}/min"
	fi

	echo "[E-H] Fetching index page..."

	# This is so that we don't get the 'offensive' warning.
	# XXX - Is this needed for Ex?

	TEMP="$(temp f)"

	# Don't wait here.
	fetch "${sitepage}/?nw=always" "$TEMP"

	while [ ! $FETCH_RESULT = 0 ]; do
		fetch "${sitepage}/?nw=always" "$TEMP"
	done

	# Unfortunately e-h has shit system. Time to code page extraction
	# I'm using pipes for clarity.
	# the last sed deals with names like fate/stay night which are invalid
	folder="$(cat "$TEMP" | grep 'title>' | sed -e 's/<title>//g'  -e 's/<\/title>//g' -e 's/ - E-Hentai Galleries//g' -e 's/ - ExHentai.org//g' -e 's|/|_|g' | entity_to_char | remove_illegal)"

	is_done "$folder"
	R=$?
	if [ $R = 1 ]; then
		echo "[E-H] Already downloaded."
		rm "./$TEMP"
		return 0
	fi

	mkdir -p "$folder"
	cd "$folder"

	page=$(cat "../$TEMP" | sed 's/0 no-repeat\"><a href=\"/\nurl:/' | sed 's/"><img alt.*//g' | grep 'url:' | sed 's/url://g')

	MAXPAGES=$(cat "../$TEMP" | grep 'Length:' | sed -e 's|.*Length:</td><td class="gdt2">||g' -e 's| pages.*||g')

	rm "../$TEMP"

	echo "[E-H] Downloading '$folder'... "

	doneyet=0

	CDNFAIL=0

	if [ "$STARTAT" = "" ]; then
		STARTAT=1
	fi

	CUR=1
	while [ $doneyet = 0 ]; do
		dl_eh_wait

		TMPHT="$(temp f)"
		fetch "${page}${extra}" "$TMPHT"

		while [ ! $FETCH_RESULT = 0 ]; do
			# For the most part, we'll not hit this unless there's network issues.
			# However, it can cause a failed fetch to go uncaught, causing next to be ''
			# And if the next loop "succeeds" with a zero length page, it will propogate
			# to next, and the 'done' check will trigger incorrectly.
			message="???"
			spinner "RETR $CUR / $MAXPAGES"

			dl_eh_wait
			fetch "${page}${extra}" "$TMPHT"
		done

		lq=$(cat "$TMPHT" | tr '<' '\n' | grep -e 'a href' -e 'img src' -e 'img id="img"' | grep -e 'keystamp' -e 'image.php' -e '/im/' | sed -e 's|.*src="||g' -e 's|".*||' | entity_to_char)
		hq=$(cat "$TMPHT" | tr '<' '\n' | grep -e 'a href' -e 'img src' -e 'img id="img"' | grep -e 'source' | sed -e 's|.*href="||g' -e 's|".*||g' | entity_to_char)
		next=$(cat "$TMPHT" | tr '<' '\n' | grep -e "-$next_cnt\"" | sed -e 's|.*href="||g' -e 's|">||g' | head -n1)
		next_cnt=$((CUR + 1))

		if [ "$VERBOSE" = "1" ]; then
			echo "This page: '$page'"
			echo "LQ Image:  '$lq'"
			echo "HQ Image:  '$hq'"
			echo "Next page: '$next'"
		fi

		spinner "IMG $CUR / $MAXPAGES"

		if (( $CUR < $STARTAT )); then
			rm "$TMPHT"
			page="$next"
			CUR=$((CUR + 1))
			continue
		fi

		if [ ! "$LOGGEDIN" = 1 ] || [ "$hq" = "" ]; then
			dl_eh_wait
			fetch "$lq" "$(basename "$lq")"
		else
			# HQ version; this is the 'Download source resolution' button.
			dl_eh_wait
			fetch "$hq"
		fi

		if [ $FETCH_RESULT = 0 ]; then
			extra=""
			CUR=$(( CUR + 1 ))
			if [ ! "$next" = "" ]; then
				page="$next"
			fi
		else
			notload=$(cat "$TMPHT" | grep 'nl(' | sed -e "s|^.*nl('||g" -e "s|'.*$||g")
			extra="?nl=${notload}"
		fi

		rm "$TMPHT"

		# This is a much saner condition than checking if next is null.
		if (( $CUR > $MAXPAGES )); then
			break
		fi

		spinner "$CUR / $MAXPAGES"
	done

	spinner_done

	cd ..

	cbz_make "$folder"
}

scrape_eh() {
	# TODO - Implement search functionality.
	FETCH=""

	# Two syntaxes; A URL, or a query followed by a mode string.
	echo "$1" | grep "e.hentai\.org/\?" 2>&1 >/dev/null
	S=$?
	if [ $S = 0 ]; then
		# This is a URL.
		FETCH="${1}&page="
	else
		# This is all broken and needs to be fixed.
		KEYW=""

		# Mode strings: dtagwnicpx
		DEFAULT=1
		M_D=$DEFAULT # Doujinshi
		M_M=$DEFAULT # Manga.
		M_A=$DEFAULT # Artist CG.
		M_G=$DEFAULT # Game CG
		M_W=$DEFAULT # Western
		M_N=$DEFAULT # Non-H
		M_I=$DEFAULT # Imageset
		M_C=$DEFAULT # Cosplay
		M_P=$DEFAULT # That category which nobody uses E-h for (maybe)
		M_X=$DEFAULT # Misc

		check_low_eh "http://exhentai.org/"
		EX_WORKS=$?

		# We *should* use exhentai if the user has access.
		if [ $EX_WORKS = 0 ]; then
			BASE_URL="http://exhentai.org/"
		else
			BASE_URL="http://g.e-hentai.org/"
		fi

		for((i=0; i<${#SUBTYPES}; i++)); do
			INDEX=${SUBTYPES:i:1}
			if [ $i = 0 ] && [ "$INDEX" = "^" ]; then
				# Invert all set values.
				[ $M_D = 0 ] && M_D=1 || M_D=0 # This is equivalent to !M_D in a 1 -> 0 -> 1 sense.
				[ $M_M = 0 ] && M_M=1 || M_M=0
				[ $M_A = 0 ] && M_A=1 || M_A=0
				[ $M_G = 0 ] && M_G=1 || M_G=0
				[ $M_W = 0 ] && M_W=1 || M_W=0
				[ $M_N = 0 ] && M_N=1 || M_N=0
				[ $M_I = 0 ] && M_I=1 || M_I=0
				[ $M_C = 0 ] && M_C=1 || M_C=0
				[ $M_P = 0 ] && M_P=1 || M_P=0
				[ $M_X = 0 ] && M_X=1 || M_X=0
			else
				case "$INDEX" in
					"d")
						[ $M_D = 0 ] && M_D=1 || M_D=0
					;;
					"m")
						[ $M_M = 0 ] && M_M=1 || M_M=0
					;;
					"a")
						[ $M_A = 0 ] && M_A=1 || M_A=0
					;;
					"g")
						[ $M_G = 0 ] && M_G=1 || M_G=0
					;;
					"w")
						[ $M_W = 0 ] && M_W=1 || M_W=0
					;;
					"n")
						[ $M_N = 0 ] && M_N=1 || M_N=0
					;;
					"i")
						[ $M_I = 0 ] && M_I=1 || M_I=0
					;;
					"c")
						[ $M_C = 0 ] && M_C=1 || M_C=0
					;;
					"p")
						[ $M_P = 0 ] && M_P=1 || M_P=0
					;;
					"x")
						[ $M_X = 0 ] && M_X=1 || M_X=0
					;;
				esac
			fi
		done

		MODE_PART="f_doujinshi=$M_D&f_manga=$M_M&f_artistcg=$M_A&f_gamecg=$M_G&f_western=$M_W&f_non-h=$M_N&f_imageset=$M_I&f_cosplay=$M_C&f_asianporn=$M_P&f_misc=$M_X"

		# Read search keywords.
		while [ ! -z "$1" ]; do
			KEYW="$KEYW+\"$(echo $1 | sed -e 's| |+|g' -e 's|:|%3A|g')\""
			shift
		done

		KEYW="$(echo $KEYW | sed 's|^\+||g')"

		FETCH="${BASE_URL}?${MODE_PART}&f_search=${KEYW}&f_apply=Apply+Filter&page="
	fi

	# Notes; page=1 is page 2. Pages are base 0 indexed.
	check_eh "${FETCH}0"

	# How many pages of shit?
	PAGE_COUNT="$(fetch "${FETCH}0" "-" | grep "Jump to page" | sed 's|.*Jump to page: (1-||g' | sed 's|).*||g' | head -n1)"

	if [ "$PAGE_COUNT" = "" ]; then
		PAGE_COUNT=1
	fi

	echo "[E-h] Pages: $PAGE_COUNT"

	TEMP="$(temp f)"

	for (( i=0 ; i < $PAGE_COUNT ; i++ )); do
		FETCH_RESULT=1
		while [ ! $FETCH_RESULT = 0 ]; do
			fetch "${FETCH}${i}" "-" >> "$TEMP"

			echo "[E-H] Grabbing page $((i + 1))..."
		done
	done

	cat "$TEMP" | sed "s|<|\n|g" | grep "a href=\"http://\(g.\)\?e.hentai.org/g/" | sed -e 's|a href="||g' -e 's|".*||g' | sort | uniq >> batch.txt
	rm "$TEMP"
}
