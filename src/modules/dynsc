dynsc_longname="Dynasty Scans"
dynsc_url="http://dynasty-scans.com/"
dynsc_state=1
dynsc_filt=0 # No filter

auto_dynsc() {
	if [ -n "`echo $1 | grep 'dynasty-scans.com/' | sed -e 's/^ *//' -e 's/[[:space:]]*$//'`" ]; then
		# Dynasty Scans.
		return 1
	fi

	return 0
}

dl_dynsc() {
	
	# Now loop-de-loop. First, make a decent name. Dynasty always has
	# a short-title at the end of the URL.

	folder="`echo $1 | sed -re 's/^.+\///'`"
	mkdir -p $folder
	cd $folder

	PAGEDATA="$(fetch "$1" "-" | grep "var pages")"

	# This set of seds cuts up the pagelist in a manner
	# that makes it identical to a bash array.
	# So we're essentially modifying the webpage into a dl-script.
	# Cool, eh?

	PAGETMP="$(echo $PAGEDATA | sed -e "s/\"image\"\://g" -e "s/,\"name\"\:\"[[:alnum:]_-]*\"//g" -e "s/\}\]/\)/g" -e "s/{//g" -e "s/}//g" -e "s/;//g" -e "s/ //g" -e "s/varpages=\[/pages=\(/g" -e "s/,/ /g")"

	# One possible nasty. Spaces.
	# sed -i "s/\%20/ /g" tmp.1

	# Load in the array.
	eval "$PAGETMP"

	echo -n "[DynastyScans] Downloading '$folder' "

	CUR=0

	for image in "${pages[@]}"; do
		fetch "http://dynasty-scans.com$image"
		spinner "$CUR"
		CUR=$(( CUR + 1 ))
	done

	done_spin
	
	cd ..

	cbz_make "$folder"
}

scrape_dynsc() {
	echo -n "[DynastyScans] Scraping Chapters..."

	fetch "$1" "scrape.htm"

	grep 'class="name"' scrape.htm > batch.txtf

	sed -i 's|^.*href="||g' batch.txtf
	sed -i 's|" class=.*||g' batch.txtf
	sed -i "s/^[[:space:]]*//" batch.txtf
	sed -i "s/[[:space:]]*$//" batch.txtf

	# URLS are local.
	sed -i "s|^|http://dynasty-scans.com|g" batch.txtf

	# Luckily, dynasty is one of the few sites that does ascending rather than descending order (txtf = forward, txtr = reversed)
	cat batch.txtf >> batch.txt

	# We've scraped a batch file from the URL list. Clean up.
	rm scrape.htm batch.txtf

	echo -e "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b[DynastyScans] Scraped chapters to batch.txt. You can modify this, or pass it to autobatch."
}
