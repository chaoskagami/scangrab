#!/bin/bash
# Copyright (C) 2015  Jon Feldman/@chaoskagami
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>

dynsc_longname="Dynasty Scans"
dynsc_url="http://dynasty-scans.com/"
dynsc_state=1
# No filter
dynsc_filt=0

auto_dynsc() {
	if [ -n "`echo $1 | grep 'dynasty-scans.com/' | sed -e 's/^ *//' -e 's/[[:space:]]*$//'`" ]; then
		# Dynasty Scans.
		return 1
	fi

	return 0
}

dl_dynsc() {
	
	# Now loop-de-loop. First, make a decent name. Dynasty always has
	# a short-title at the end of the URL.

	PAGEDATA="$(fetch "$1" "-")"

	folder="$(echo "$PAGEDATA" | grep "<title>" | sed -e 's/<title>Dynasty Reader &raquo; //g' -e 's|</title>||g')"

	mkdir -p "$folder"
	cd "$folder"

	PAGELIST="$(echo "$PAGEDATA" | grep "var pages")"

	# This set of seds cuts up the pagelist in a manner
	# that makes it identical to a bash array.
	# So we're essentially modifying the webpage into a dl-script.
	# Cool, eh?

	PAGETMP="$(echo $PAGELIST | sed -e "s/\"image\"\://g" -e "s/,\"name\"\:\"[[:alnum:]_-]*\"//g" -e "s/\}\]/\)/g" -e "s/{//g" -e "s/}//g" -e "s/;//g" -e "s/ //g" -e "s/varpages=\[/pages=\(/g" -e "s/,/ /g")"

	# One possible nasty. Spaces.
	# sed -i "s/\%20/ /g" tmp.1

	# Load in the array.
	eval "$PAGETMP"

	echo -n "[DynastyScans] Downloading '$folder' "

	CUR=0

	for image in "${pages[@]}"; do
		fetch "http://dynasty-scans.com$image"
		spinner "$CUR"
		CUR=$(( CUR + 1 ))
	done

	spinner_done
	
	cd ..

	cbz_make "$folder"
}

scrape_dynsc() {
	echo -n "[DynastyScans] Scraping Chapters..."

	# URLS are local.
	fetch "$1" "-" | 			\
	grep 'class="name"' | 		\
	sed -e 's|^.*href="||g' 	\
		-e 's|" class=.*||g' 	\
		-e "s/^[[:space:]]*//" 	\
		-e "s/[[:space:]]*$//" 	\
		-e "s|^|http://dynasty-scans.com|g" >> batch.txt

	echo -e "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b[DynastyScans] Scraped chapters to batch.txt. You can modify this, or pass it to autobatch."
}
